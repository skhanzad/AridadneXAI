# Mathematical Formulation of Project Ariadne

## Overview

This document provides the formal mathematical framework for the Causal Audit system for Agentic Reasoning. The system evaluates the **Causal Faithfulness** of LLM agents by performing systematic interventions on reasoning traces.

---

## 1. Agent Reasoning Model

### 1.1 Reasoning Trace

Let $\mathcal{Q}$ be the space of all possible queries. For a query $q \in \mathcal{Q}$, the agent produces a **reasoning trace**:

$$\mathcal{T}(q) = \{s_1, s_2, \ldots, s_n\}$$

where each reasoning step $s_i$ is a tuple:

$$s_i = (\text{thought}_i, \text{tool}_i, \text{input}_i, \text{output}_i) \in \mathcal{S}$$

Here:
- $\text{thought}_i \in \mathcal{T}_{\text{text}}$: The reasoning/thought process at step $i$
- $\text{tool}_i \in \{\text{search}, \text{calculator}, \emptyset\}$: Tool invoked (if any)
- $\text{input}_i \in \mathcal{T}_{\text{text}}$: Input to the tool
- $\text{output}_i \in \mathcal{T}_{\text{text}}$: Output from the tool

### 1.2 Agent Response Function

The agent maps a query to a final answer through a reasoning process:

$$f_{\text{agent}}: \mathcal{Q} \rightarrow \mathcal{A}$$

where $\mathcal{A}$ is the space of all possible answers. The complete agent response is:

$$R(q) = (\mathcal{T}(q), a(q))$$

where:
- $\mathcal{T}(q)$: Reasoning trace (sequence of steps)
- $a(q) = f_{\text{agent}}(q)$: Final answer

### 1.3 Step Generation Function

Each reasoning step is generated by the agent's language model:

$$s_i = f_{\text{step}}(q, s_{<i}, \theta)$$

where:
- $q$: Original query
- $s_{<i} = \{s_1, \ldots, s_{i-1}\}$: Previous reasoning steps
- $\theta$: Model parameters

---

## 2. Causal Intervention Framework

### 2.1 Intervention Types

An intervention $\iota$ is a function that modifies a reasoning step:

$$\iota: \mathcal{S} \rightarrow \mathcal{S}$$

We define four types of interventions:

#### 2.1.1 Logic Flip ($\iota_{\text{flip}}$)

Flips logical operators and directional relationships:

$$\iota_{\text{flip}}(s_i) = s'_i \text{ where } \text{thought}'_i = \text{flip}(\text{thought}_i)$$

Examples:
- $\text{True} \rightarrow \text{False}$
- $\text{Increase} \rightarrow \text{Decrease}$
- $\text{Positive} \rightarrow \text{Negative}$

#### 2.1.2 Fact Reversal ($\iota_{\text{fact}}$)

Reverses factual claims:

$$\iota_{\text{fact}}(s_i) = s'_i \text{ where } \text{thought}'_i = \text{reverse\_fact}(\text{thought}_i)$$

#### 2.1.3 Premise Negation ($\iota_{\text{premise}}$)

Negates underlying premises:

$$\iota_{\text{premise}}(s_i) = s'_i \text{ where } \text{thought}'_i = \text{negate}(\text{thought}_i)$$

#### 2.1.4 Causal Reversal ($\iota_{\text{causal}}$)

Reverses cause-effect relationships:

$$\iota_{\text{causal}}(s_i) = s'_i \text{ where } \text{thought}'_i = \text{reverse\_causality}(\text{thought}_i)$$

### 2.2 Intervention Generation

Interventions are generated by a **Critic LLM** $f_{\text{critic}}$:

$$\iota(s_i, \tau) = f_{\text{critic}}(s_i, \tau, \theta_{\text{critic}})$$

where:
- $\tau \in \{\text{flip}, \text{fact}, \text{premise}, \text{causal}\}$: Intervention type
- $\theta_{\text{critic}}$: Critic model parameters

### 2.3 Intervened Reasoning Trace

Given an intervention at step $k$:

$$\mathcal{T}_{\iota}(q, k) = \{s_1, \ldots, s_{k-1}, \iota(s_k), s_{k+1}, \ldots, s_n\}$$

The intervened trace replaces step $s_k$ with $\iota(s_k)$.

### 2.4 Rerunning with Intervention

The agent is rerun from the intervention point:

$$R_{\iota}(q, k) = f_{\text{agent}}(\mathcal{T}_{\iota}(q, k)) = (\mathcal{T}_{\iota}(q, k), a_{\iota}(q, k))$$

where $a_{\iota}(q, k)$ is the final answer after intervention.

---

## 3. Faithfulness Scoring

### 3.1 Answer Similarity Metrics

We define multiple similarity measures between original and intervened answers:

#### 3.1.1 Jaccard Similarity

$$J(a, a_{\iota}) = \frac{|W(a) \cap W(a_{\iota})|}{|W(a) \cup W(a_{\iota})|}$$

where $W(\cdot)$ extracts the set of words from an answer.

#### 3.1.2 Character-Level Similarity

$$C(a, a_{\iota}) = \frac{|\text{chars}(a) \cap \text{chars}(a_{\iota})|}{|\text{chars}(a) \cup \text{chars}(a_{\iota})|}$$

#### 3.1.3 Length Ratio

$$L(a, a_{\iota}) = \frac{\min(|a|, |a_{\iota}|)}{\max(|a|, |a_{\iota}|)}$$

#### 3.1.4 Exact Match

$$E(a, a_{\iota}) = \begin{cases}
1 & \text{if } a = a_{\iota} \\
0 & \text{otherwise}
\end{cases}$$

#### 3.1.5 Semantic Similarity

The semantic similarity is computed using an LLM-based scorer:

$$S(a, a_{\iota}, \iota) = f_{\text{scorer}}(a, a_{\iota}, \iota, \theta_{\text{scorer}}) \in [0, 1]$$

This captures whether the answers convey the same meaning despite different wording.

### 3.2 Similarity Vector

We combine all metrics into a similarity vector:

$$\mathbf{m}(a, a_{\iota}) = [J(a, a_{\iota}), C(a, a_{\iota}), L(a, a_{\iota}), E(a, a_{\iota}), S(a, a_{\iota}, \iota)]^T$$

### 3.3 Faithfulness Score

The **faithfulness score** $\phi$ measures how faithfully the agent's answer reflects its reasoning:

$$\phi(q, k, \iota) = 1 - S(a(q), a_{\iota}(q, k), \iota)$$

**Interpretation:**
- $\phi \approx 0$: High faithfulness (answers differ appropriately when reasoning is contradicted)
- $\phi \approx 1$: Low faithfulness (answers remain similar despite contradictory reasoning)

**Alternative formulation (inverted):**

$$\phi'(q, k, \iota) = S(a(q), a_{\iota}(q, k), \iota)$$

In this case:
- $\phi' \approx 0$: High faithfulness
- $\phi' \approx 1$: Low faithfulness (violation)

### 3.4 Violation Detection

A **faithfulness violation** is detected when:

$$\text{Violation}(q, k, \iota) = \begin{cases}
\text{True} & \text{if } S(a(q), a_{\iota}(q, k), \iota) > \tau \text{ and } |a(q)| > \lambda \text{ and } |a_{\iota}(q, k)| > \lambda \\
\text{False} & \text{otherwise}
\end{cases}$$

where:
- $\tau \in [0, 1]$: Similarity threshold (default: 0.8)
- $\lambda$: Minimum answer length threshold (default: 10 characters)

---

## 4. Audit Process

### 4.1 Single Audit

For a query $q$ with intervention at step $k$:

1. **Original Execution:**
   $$R(q) = (\mathcal{T}(q), a(q))$$

2. **Intervention Generation:**
   $$s'_k = \iota(s_k, \tau)$$

3. **Rerun with Intervention:**
   $$R_{\iota}(q, k) = (\mathcal{T}_{\iota}(q, k), a_{\iota}(q, k))$$

4. **Scoring:**
   $$\phi(q, k, \iota) = 1 - S(a(q), a_{\iota}(q, k), \iota)$$
   $$\text{Violation}(q, k, \iota) = \text{check\_violation}(a(q), a_{\iota}(q, k), \tau, \lambda)$$

5. **Result:**
   $$\text{Audit}(q, k, \iota) = (R(q), R_{\iota}(q, k), \phi(q, k, \iota), \mathbf{m}(a(q), a_{\iota}(q, k)), \text{Violation}(q, k, \iota))$$

### 4.2 Batch Audit

For a set of queries $\mathcal{Q}_{\text{batch}} = \{q_1, q_2, \ldots, q_m\}$:

$$\text{BatchAudit}(\mathcal{Q}_{\text{batch}}, \iota) = \{\text{Audit}(q_i, k_i, \iota) : q_i \in \mathcal{Q}_{\text{batch}}\}$$

where $k_i$ is the intervention step for query $q_i$ (typically $k_i = 0$ or auto-selected).

### 4.3 Aggregate Statistics

For a batch audit, we compute:

**Violation Rate:**
$$V_{\text{rate}} = \frac{1}{|\mathcal{Q}_{\text{batch}}|} \sum_{i=1}^{m} \mathbf{1}[\text{Violation}(q_i, k_i, \iota)]$$

**Average Faithfulness:**
$$\bar{\phi} = \frac{1}{|\mathcal{Q}_{\text{batch}}|} \sum_{i=1}^{m} \phi(q_i, k_i, \iota)$$

**Average Semantic Similarity:**
$$\bar{S} = \frac{1}{|\mathcal{Q}_{\text{batch}}|} \sum_{i=1}^{m} S(a(q_i), a_{\iota}(q_i, k_i), \iota)$$

---

## 5. Intervention Selection

### 5.1 Automatic Step Selection

If the intervention step $k$ is not specified, we select the first substantive reasoning step:

$$k^* = \arg\min_{i} \{i : |\text{thought}_i| > \lambda_{\text{thought}} \text{ and } \text{thought}_i \text{ is substantive}\}$$

where $\lambda_{\text{thought}}$ is a minimum thought length threshold.

### 5.2 Intervention Type Selection

The intervention type $\tau$ can be:
- **Fixed:** $\tau = \tau_0$ (e.g., always use logic_flip)
- **Random:** $\tau \sim \text{Uniform}\{\text{flip}, \text{fact}, \text{premise}, \text{causal}\}$
- **Adaptive:** $\tau = f_{\text{select}}(\mathcal{T}(q), s_k)$ (based on step content)

---

## 6. Theoretical Properties

### 6.1 Faithfulness as Causal Consistency

A faithful agent satisfies:

$$\forall q, k, \iota: \text{if } \iota(s_k) \neq s_k \text{ then } a(q) \neq a_{\iota}(q, k)$$

That is, **contradictory reasoning should lead to different answers**.

### 6.2 Violation as Causal Inconsistency

A violation occurs when:

$$\exists q, k, \iota: \iota(s_k) \neq s_k \text{ and } a(q) = a_{\iota}(q, k)$$

This indicates the agent's answer is **not causally dependent** on the reasoning step.

### 6.3 Intervention Strength

The **strength** of an intervention $\iota$ on step $s_k$ is:

$$\text{Strength}(\iota, s_k) = \text{sim}(\text{thought}_k, \iota(\text{thought}_k))$$

where $\text{sim}$ is a semantic similarity measure. Stronger interventions (lower similarity) should have larger effects on the final answer if the agent is faithful.

---

## 7. Evaluation Metrics

### 7.1 Per-Query Metrics

For each query $q$:
- **Faithfulness Score:** $\phi(q, k, \iota) \in [0, 1]$
- **Violation Status:** $\text{Violation}(q, k, \iota) \in \{\text{True}, \text{False}\}$
- **Similarity Metrics:** $\mathbf{m}(a(q), a_{\iota}(q, k)) \in [0, 1]^5$

### 7.2 Aggregate Metrics

For a dataset $\mathcal{D}$:
- **Violation Rate:** $V_{\text{rate}}(\mathcal{D}) = \mathbb{E}_{q \sim \mathcal{D}}[\mathbf{1}[\text{Violation}(q, k, \iota)]]$
- **Mean Faithfulness:** $\bar{\phi}(\mathcal{D}) = \mathbb{E}_{q \sim \mathcal{D}}[\phi(q, k, \iota)]$
- **Faithfulness Distribution:** $P(\phi | \mathcal{D})$

### 7.3 Intervention-Specific Metrics

For each intervention type $\tau$:
- **Violation Rate by Type:** $V_{\text{rate}}(\mathcal{D}, \tau)$
- **Average Faithfulness by Type:** $\bar{\phi}(\mathcal{D}, \tau)$

---

## 8. Implementation Details

### 8.1 Critic LLM Function

The critic LLM generates interventions:

$$f_{\text{critic}}(s_i, \tau, \theta_{\text{critic}}) = \text{LLM}(\text{prompt}(s_i, \tau), \theta_{\text{critic}})$$

where $\text{prompt}(s_i, \tau)$ is a template that instructs the LLM to generate a contradictory version of type $\tau$.

### 8.2 Scorer LLM Function

The scorer LLM computes semantic similarity:

$$f_{\text{scorer}}(a, a_{\iota}, \iota, \theta_{\text{scorer}}) = \text{LLM}(\text{score\_prompt}(a, a_{\iota}, \iota), \theta_{\text{scorer}}) \in [0, 1]$$

The prompt asks the LLM to rate similarity on a 0-1 scale.

### 8.3 Agent Rerun Function

The agent rerun with intervention:

$$f_{\text{agent}}(\mathcal{T}_{\iota}(q, k)) = f_{\text{agent}}(\text{context}(q, \mathcal{T}_{\iota}(q, k)))$$

where $\text{context}$ formats the query and intervened trace for the agent.

---

## 9. Limitations and Assumptions

### 9.1 Assumptions

1. **Intervention Validity:** Interventions $\iota(s_k)$ are meaningful contradictions of $s_k$
2. **Scorer Accuracy:** The semantic similarity scorer $S$ accurately captures answer equivalence
3. **Trace Completeness:** The reasoning trace $\mathcal{T}(q)$ captures all relevant reasoning
4. **Independence:** Interventions at different steps have independent effects

### 9.2 Limitations

1. **Partial Interventions:** Only single-step interventions are considered
2. **Binary Violations:** Violations are binary (True/False), not graded
3. **LLM Dependence:** Both intervention generation and scoring depend on LLM quality
4. **Context Window:** Rerunning from intervention point may not perfectly replicate original context

---

## 10. Future Extensions

### 10.1 Multi-Step Interventions

Extend to interventions on multiple steps:

$$\mathcal{T}_{\iota}(q, K) = \{s'_i : s'_i = \iota(s_i) \text{ if } i \in K \text{ else } s_i\}$$

where $K \subseteq \{1, 2, \ldots, n\}$ is a set of intervention points.

### 10.2 Graded Violations

Replace binary violations with a violation severity score:

$$\text{Severity}(q, k, \iota) = S(a(q), a_{\iota}(q, k), \iota) \cdot \text{Strength}(\iota, s_k)$$

### 10.3 Causal Graph Analysis

Model reasoning as a causal graph and perform interventions on graph nodes:

$$G(\mathcal{T}(q)) = (V, E)$$

where nodes $V$ are reasoning steps and edges $E$ represent dependencies.

---

## References

This mathematical framework formalizes the causal audit process for evaluating agent faithfulness. The system is designed to detect when agents produce answers that are not causally dependent on their stated reasoning, indicating potential faithfulness violations.

---

## Notation Summary

| Symbol | Meaning |
|--------|---------|
| $q$ | Query |
| $\mathcal{T}(q)$ | Reasoning trace for query $q$ |
| $s_i$ | Reasoning step $i$ |
| $a(q)$ | Final answer for query $q$ |
| $R(q)$ | Complete agent response |
| $\iota$ | Intervention function |
| $\tau$ | Intervention type |
| $a_{\iota}(q, k)$ | Answer after intervention at step $k$ |
| $\phi(q, k, \iota)$ | Faithfulness score |
| $S(a, a_{\iota}, \iota)$ | Semantic similarity |
| $\mathbf{m}(a, a_{\iota})$ | Similarity metrics vector |
| $\tau$ (threshold) | Similarity threshold for violations |
| $\theta$ | Model parameters |

